{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "DZ_1.ipynb",
      "collapsed_sections": [
        "KOoeM9gyNIq9"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPP1GcpAG6jTPe9E/rJAupo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denhin-ii/Deep-Learning-with-Pytorch/blob/main/DZ_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание N1"
      ],
      "metadata": {
        "id": "7LD6p91qXiPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 0\n",
        " Создайте репозиторий на Github. Вся дальнейшая домашка загружается туда. Чуть позже в телеграм чате будет выложена форма для сдачи.\n"
      ],
      "metadata": {
        "id": "1rbDuDpBIbOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5l8JhIO_NGn0"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 1 \n",
        "реализуйте XOR с помощью 3 нейронов. Запишите ответ в виде выражения, состоящего из объектов neuron() – моделей нейрона с пороговой функцией активации, внутри скобок может быть что угодно. Входы верхнего уровня называются x1 и x2. Пример фрагмента записи: neuron(1x1 + 5x2 - 0.1) + neuron(x1) (ответ будет выглядеть чуть сложнее, но других символов вроде && не потребуется).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KOoeM9gyNIq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "И"
      ],
      "metadata": {
        "id": "PTDKvIM9r6XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ],
      "metadata": {
        "id": "7dvDtA7HX3V6"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Est1tKg1WDdG",
        "outputId": "2749c7c2-9238-42f5-fc28-aa8bd07309f0"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[ 0.3311, -0.6208]], requires_grad=True), Parameter containing:\n",
              " tensor([0.1571], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
        "neuron.fc.bias.data = torch.tensor([0.0])"
      ],
      "metadata": {
        "id": "kAtwMX7HQ0aj"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "P27EdNkrXloh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7116bb3c-240f-47ab-fe0a-fa3edd0d809d"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!(или)"
      ],
      "metadata": {
        "id": "SUFDTfUrr8eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, y):\n",
        "    return torch.heaviside(self.fc(y), torch.tensor([1.0]))"
      ],
      "metadata": {
        "id": "GG-PAZpQoIJz"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e2794d-94dd-427c-bbee-4fc11a8f1d7a",
        "id": "I3yBm3gJoIJ6"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-0.6210,  0.0294]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.6107], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
        "neuron.fc.bias.data = torch.tensor([1.0])"
      ],
      "metadata": {
        "id": "hWP7ee7tjCGv"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([0.0, 0.0])\n",
        "neuron(y)"
      ],
      "metadata": {
        "id": "HgDrZ7PBjGwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7e7714-20a7-4a9f-fadc-c7cd472565b6"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "или"
      ],
      "metadata": {
        "id": "0wcrAI6MrPWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, y):\n",
        "    return torch.heaviside(self.fc(c), torch.tensor([1.0]))"
      ],
      "metadata": {
        "id": "wueLVPAcrGxe"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XVtddKssHnO",
        "outputId": "47051424-1bc7-4bdf-bab3-66e98b2f5e1e"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[ 0.6907, -0.5092]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.3984], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[1.0, 1.0]])\n",
        "neuron.fc.bias.data = torch.tensor([1.0])"
      ],
      "metadata": {
        "id": "3bnaQsa-rGxf"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.tensor([1.0, 1.0])\n",
        "neuron(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c86b6d1-72fd-4b02-e11e-a02a494c9c70",
        "id": "y7xErlvtrGxf"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 2 \n",
        "нарисуйте backward граф для выражения a*b+c*d. [Теория и пример оформления.](https://www.youtube.com/watch?v=MswxJw-8PvE) Сравните полученные теоретические значения с аттрибутами grad у исходных тензоров."
      ],
      "metadata": {
        "id": "FIyBrvxpNK7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2.0], requires_grad=True)\n",
        "b = torch.tensor([4.0], requires_grad=True)\n",
        "c = torch.tensor([1.0], requires_grad=True)\n",
        "d = torch.tensor([5.0], requires_grad=False)"
      ],
      "metadata": {
        "id": "r60vPa3hNQF5"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMw4INvMNQQ7",
        "outputId": "31033394-3306-40be-ab69-9a2ec27e1aba"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = a*b + c*d\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "WUcY2Y9DNQYV"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qVKSyMuNQgt",
        "outputId": "81d7d94a-ed68-4c70-97b1-d64bb5b650ce"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 3\n",
        " Поэксперементируйте с размером тензоров, которые влезут на видеоркарту в Colab. Найдите максимальный размер тензора для типа данных float32, float64, float16, int32, int64. На сколько они отличаются."
      ],
      "metadata": {
        "id": "aBDV4jW1YSAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False)\n",
        "# для float16\n",
        "a = None\n",
        "try:\n",
        "a = torch.rand(3_800_500_000*2, dtype=torch.float16, device='cuda')\n",
        "except:\n",
        "pass\n",
        "finally:\n",
        "del a\n",
        "\n",
        "print(gc.collect())\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_reserved(), torch.cuda.memory_allocated())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "_P553K5Y004n",
        "outputId": "a15cf10a-92c4-41a6-f84f-ca71cb038243"
      },
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-322-7573d5963e0d>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    a = torch.rand(3_800_500_000*2, dtype=torch.float16, device='cuda')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 4\n",
        "Напишите хороший пример неэффективного кода для занятия памяти видеокарты, который вызовет ошибку out of memory"
      ],
      "metadata": {
        "id": "YbOcaY8LYTmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "name = \"a\" * 50\n",
        "del name\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "54-kMyegdukA",
        "outputId": "21fec1ba-d0d8-43a8-8c2e-ed7a41d9a733"
      },
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-316-eba106bbcf52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"a\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 5\n",
        "Используя один линейный слой nn.Linear и один входной тензор x подберите подберите размерности так, чтобы занимать всю видеопамять. Попробуйте применить линейный слой к тензору x. Что произойдет? Кратко опишите ваши эксперименты. Что вы поняли?"
      ],
      "metadata": {
        "id": "KIuZduuXYV_V"
      }
    }
  ]
}