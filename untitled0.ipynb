{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOnfYrUIg6NGuyBJJVMmGrs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denhin-ii/Deep-Learning-with-Pytorch/blob/main/untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание N1"
      ],
      "metadata": {
        "id": "7LD6p91qXiPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 0\n",
        " Создайте репозиторий на Github. Вся дальнейшая домашка загружается туда. Чуть позже в телеграм чате будет выложена форма для сдачи.\n"
      ],
      "metadata": {
        "id": "1rbDuDpBIbOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5l8JhIO_NGn0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 1 \n",
        "реализуйте XOR с помощью 3 нейронов. Запишите ответ в виде выражения, состоящего из объектов neuron() – моделей нейрона с пороговой функцией активации, внутри скобок может быть что угодно. Входы верхнего уровня называются x1 и x2. Пример фрагмента записи: neuron(1x1 + 5x2 - 0.1) + neuron(x1) (ответ будет выглядеть чуть сложнее, но других символов вроде && не потребуется).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KOoeM9gyNIq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ],
      "metadata": {
        "id": "7dvDtA7HX3V6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "Est1tKg1WDdG",
        "outputId": "9de2dfe2-5ea8-4d76-b9bb-19d6dd9dd5c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[0.0179, 0.3740]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.1958], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
        "neuron.fc.bias.data = torch.tensor([0.0])"
      ],
      "metadata": {
        "id": "kAtwMX7HQ0aj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "P27EdNkrXloh",
        "outputId": "8e37ca4c-b366-4660-f095-2d5f57d24c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
        "neuron.fc.bias.data = torch.tensor([0.0])"
      ],
      "metadata": {
        "id": "hWP7ee7tjCGv",
        "outputId": "ff2e94a3-5c10-4a9a-dd03-22e0c92c66d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-193525512fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1208\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Neuron' object has no attribute 'fc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "HgDrZ7PBjGwJ",
        "outputId": "1b424f36-ce2c-4600-e6d0-08284cbfa18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7543ba148714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mneuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 2 \n",
        "нарисуйте backward граф для выражения a*b+c*d. [Теория и пример оформления.](https://www.youtube.com/watch?v=MswxJw-8PvE) Сравните полученные теоретические значения с аттрибутами grad у исходных тензоров."
      ],
      "metadata": {
        "id": "FIyBrvxpNK7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2.0], requires_grad=True)\n",
        "b = torch.tensor([4.0], requires_grad=True)\n",
        "c = torch.tensor([1.0], requires_grad=True)\n",
        "d = torch.tensor([5.0], requires_grad=False)"
      ],
      "metadata": {
        "id": "r60vPa3hNQF5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad)"
      ],
      "metadata": {
        "id": "RMw4INvMNQQ7",
        "outputId": "8fc4ce38-0087-4c56-f55e-47f8891828ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = a*b + c*d\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "WUcY2Y9DNQYV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad)"
      ],
      "metadata": {
        "id": "1qVKSyMuNQgt",
        "outputId": "3701d600-1ba6-4bf5-970a-3c38cedb2d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8.])\n",
            "tensor([4.])\n",
            "tensor([10.])\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 3\n",
        " Поэксперементируйте с размером тензоров, которые влезут на видеоркарту в Colab. Найдите максимальный размер тензора для типа данных float32, float64, float16, int32, int64. На сколько они отличаются."
      ],
      "metadata": {
        "id": "aBDV4jW1YSAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 4\n",
        "Напишите хороший пример неэффективного кода для занятия памяти видеокарты, который вызовет ошибку out of memory"
      ],
      "metadata": {
        "id": "YbOcaY8LYTmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание 5\n",
        "Используя один линейный слой nn.Linear и один входной тензор x подберите подберите размерности так, чтобы занимать всю видеопамять. Попробуйте применить линейный слой к тензору x. Что произойдет? Кратко опишите ваши эксперименты. Что вы поняли?"
      ],
      "metadata": {
        "id": "KIuZduuXYV_V"
      }
    }
  ]
}